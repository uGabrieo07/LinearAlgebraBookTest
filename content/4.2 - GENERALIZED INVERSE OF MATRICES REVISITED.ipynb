{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40348e36-adf4-45eb-9d02-83da0e7eb75b",
   "metadata": {},
   "source": [
    "## The Generalized Inverse of Matrices Revisited\n",
    "\n",
    "The $\\mathbf{P}\\mathbf{L}\\mathbf{U}$ decomposition is a nice algorithmic\n",
    "method that allows the solution of systems of simultaneous equations,\n",
    "$\\mathbf{A}\\mathbf{x}=\\mathbf{b}$, without explicitly calculating the\n",
    "inverse of matrix $\\mathbf{A}$, whenever it exists. For $\\mathbf{A}$\n",
    "invertible, $\\mathbf{A}^{-1}$ is unique, the solution of the system of\n",
    "equations is also unique, but we may not need to calculate\n",
    "$\\mathbf{A}^{-1}$ after all when solving for $\\mathbf{x}$. However, when\n",
    "the system admits an infinite number of solutions, we may wonder how to\n",
    "proceed.\n",
    "\n",
    "Let $\\mathbf{A}:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$ be a linear\n",
    "transformation induced by matrix $\\mathbf{A}$, with $n\\le m$ and\n",
    "$\\text{rank}(\\mathbf{A})=r\\le n$. The case in which $n>m$ will be\n",
    "treated afterwards. We can always decompose\n",
    "$\\mathbf{A}=\\mathbf{P}\\mathbf{L}\\mathbf{U}$, with $\\mathbf{P}$ and\n",
    "$\\mathbf{L}$ both square invertible matrices, and $\\mathbf{U}$ upper\n",
    "triangular as follows: $$\\mathbf{U}=\\left[\\begin{matrix}\n",
    "      \\mathbf{u}_1^{\\rm T}\\\\\n",
    "      \\mathbf{u}_2^{\\rm T}\\\\\n",
    "      \\vdots\\\\\n",
    "      \\mathbf{u}_r^{\\rm T}\\\\\n",
    "      \\mathbf{0^{\\rm T}}\\\\\n",
    "      \\vdots\\\\\n",
    "      \\mathbf{0^{\\rm T}}\n",
    "    \\end{matrix}\\right]\n",
    "    =\n",
    "    \\left[\\begin{matrix}\n",
    "      \\mathbf{U}_1^{\\rm T}\\\\\n",
    "      \\mathbf{0}\n",
    "    \\end{matrix}\\right]$$ in which $\\mathbf{u}_i\\in\\mathbb{R}^m$,\n",
    "$i=1,\\ 2,\\ \\ldots,\\ r$, are linearly independent vectors. If we wish to\n",
    "find a matrix $\\mathbf{B}$ that satisfies the first two Penrose\n",
    "equations defined in [2.6](https://martinamj.github.io/Online-Linear-Algebra/lab/index.html?path=2.6+-+GENERALIZED+INVERSE+AND+PENROSE+EQUATIONS.ipynb), rewriten\n",
    "here for convinience, \n",
    "$$\\begin{split}\n",
    "    &\\mathbf{A}\\mathbf{B}\\mathbf{A}=\\mathbf{A}\\\\\n",
    "    &\\mathbf{B}\\mathbf{A}\\mathbf{B}=\\mathbf{B}\n",
    "  \\end{split}$$ \n",
    "then it suffices to write, for\n",
    "$\\mathbf{A}=\\mathbf{P}\\mathbf{L}\\mathbf{U}$,\n",
    "$$\\mathbf{B}= \\mathbf{U}^\\#\\mathbf{L}^{-1}\\mathbf{P}^{-1}$$ where\n",
    "$\\mathbf{U}^\\#$ is a matrix with $m$ rows and $n$ columns, of which the\n",
    "first $r$ have the right inverse of $\\mathbf{U}_1^{\\rm T}$, and the\n",
    "remaining $n-r$ columns are zero, i.e., $$\\mathbf{U}^\\# = \n",
    "    \\left[\\begin{matrix}\\mathbf{u}_1^\\# & \\mathbf{u}_2^\\# & \\cdots & \\mathbf{u}_r^\\# & \\mathbf{0} & \\cdots & \\mathbf{0}\n",
    "    \\end{matrix}\\right]$$ and\n",
    "$$\\mathbf{U}_1^{\\rm T}\\mathbf{U}^\\#=\\left[\\begin{matrix}\\mathbf{I}& \\mathbf{0}\\end{matrix}\\right]$$\n",
    "with\n",
    "$$<\\mathbf{u}_i^\\#,\\mathbf{u}_j>=\\begin{cases}1, \\quad &i=j\\\\0,& \\text{otherwise}\\end{cases}$$\n",
    "The reader is invited to verify that the condition of the $n-r$ columns\n",
    "equal to zero in the definition of $\\mathbf{U}^\\#$ is sufficient for the\n",
    "first Penrose equation, but necessary for satisfying both Penrose\n",
    "equations written above.\n",
    "\n",
    "However, if we wish to find the generalized inverse,\n",
    "$\\mathbf{A}^\\dagger$, also called the Moore-Penrose inverse, then all\n",
    "four Penrose equations need to be satisfied, i.e., $$\\begin{split}\n",
    "    &\\mathbf{A}\\mathbf{A}^\\dagger\\mathbf{A}=\\mathbf{A}\\\\\n",
    "    &\\mathbf{A}^\\dagger\\mathbf{A}\\mathbf{A}^\\dagger=\\mathbf{A}^\\dagger\\\\\n",
    "    &(\\mathbf{A}\\mathbf{A}^\\dagger)^{\\rm T}=\\mathbf{A}\\mathbf{A}^\\dagger\\\\\n",
    "    &(\\mathbf{A}^\\dagger\\mathbf{A})^{\\rm T}=\\mathbf{A}^\\dagger\\mathbf{A}\n",
    "  \\end{split}$$ In this case, we need a full rank decomposition of\n",
    "$\\mathbf{A}$. Let $\\mathbf{A}:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$ be a\n",
    "linear transformation induced by matrix $\\mathbf{A}$, with $n\\le m$ and\n",
    "$\\text{rank}(\\mathbf{A})=r\\le n$. Let\n",
    "$\\mathbf{Q}:\\mathbb{R}^r\\rightarrow\\mathbb{R}^n$ be a matrix whose $r$\n",
    "columns are linearly independent and span the range of $\\mathbf{A}$,\n",
    "i.e., $\\mathcal{R}(\\mathbf{Q})=\\mathcal{R}(\\mathbf{A})$. Therefore each\n",
    "column $\\mathbf{a}_i$, $i=1,\\ 2,\\\n",
    "  \\ldots,\\ m$, of $\\mathbf{A}$ can be written as a linear combination of\n",
    "the columns $\\{\\mathbf{q}_i\\}$, $i=1,\\ 2,\\\n",
    "  \\ldots,\\ r$, of $\\mathbf{Q}$,\n",
    "$$\\mathbf{a}_i = \\sum_{j=1}^r r_{ji}\\mathbf{q}_j$$ and\n",
    "$\\mathbf{A}=\\mathbf{Q}\\mathbf{R}$, where\n",
    "$\\mathbf{R}:\\mathbb{R}^m\\rightarrow\\mathbb{R}^r$ is the matrix with the\n",
    "elements $r_{ji}$ above. Both matrices $\\mathbf{Q}$ and $\\mathbf{R}$\n",
    "have rank $r$. $\\mathbf{Q}$ has $r$ linearly independent columns,\n",
    "therefore $\\text{rank}(\\mathbf{Q})=r$. $\\mathbf{R}$ has to have rank $r$\n",
    "because it has $r$ rows, therefore $\\text{rank}(\\mathbf{R})\\le r$, but\n",
    "$r=\\text{rank}(\\mathbf{A})=\\text{rank}(\\mathbf{Q}\\mathbf{R})\\le\\min(\\text{rank}(\\mathbf{Q}),\\text{rank}(\\mathbf{R}))$.\n",
    "Therefore $\\mathbf{R}$ has $r$ linearly independent rows. For such\n",
    "decomposition, which exists for all matrices $\\mathbf{A}$, we can\n",
    "calculate the generalized inverse of matrix $\\mathbf{A}$ as\n",
    "$$\\mathbf{A}^\\dagger = \\mathbf{R}^{\\rm T}\\left(\\mathbf{Q}^{\\rm T}\\mathbf{A}\\mathbf{R}^{\\rm T}\\right)^{-1}\\mathbf{Q}^{\\rm T}$$\n",
    "The inverse\n",
    "$\\left(\\mathbf{Q}^{\\rm T}\\mathbf{A}\\mathbf{R}^{\\rm T}\\right)^{-1}$ is\n",
    "guaranteed to exist, for\n",
    "$\\mathbf{Q}^{\\rm T}\\mathbf{A}\\mathbf{R}^{\\rm T}$ is a square $r\\times r$\n",
    "matrix with\n",
    "$\\text{rank}(\\mathbf{Q}^{\\rm T}\\mathbf{A}\\mathbf{R}^{\\rm T})=r$.\n",
    "Verification that $\\mathbf{A}^\\dagger$ satisfies all four Penrose\n",
    "equations is straightforward.\n",
    "\n",
    "The case where $\\mathbf{A}:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$ with\n",
    "$m<n$ and $\\text{rank}(\\mathbf{A})=r\\le m$ is similar, and the\n",
    "expression for the generalized inverse is the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0fff7-a5e6-445b-84ce-600067e3880c",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "This chapter gave us a way to find the generalized inverse of a matrix using PLU decomposition. \n",
    "\n",
    "We know that non-square matrices may not have a unique inverse matrix. In this case, we can seach for a matrix $Gy=x$ such that $Ax = y \\rightarrow AGy = y$. Equivalently, we can define: $AGA = A$. Matrix $G$ may not be unique, therefore, for each pair $(x,y)$, its respective $G$ matrix is different from that of other pairs. In such cases, since it is impossible to find an unique matrix that gives $x$, given $y$, we may look for an unique matrix $\\tilde{G}$ that gives the nearest possible $\\tilde{x}$ to $x$ given $y$. Notice that this is not an inverse, because $\\tilde{x} \\neq x$. Remember that $\\tilde{G}$ is a pseudo-inverse. In more mathematical terms: $\\tilde{G}$ is such that $\\tilde{G}y=\\tilde{x}, \\tilde{x} = argmin_{x}||Ax - y||$\n",
    "\n",
    "The pseudo-inverse that solves the problem above is called a least squares pseudo-inverse. \n",
    "\n",
    "All least squared generalized inverses are Moore-Penrose generalized inverses. Can you prove that?\n",
    "\n",
    "In the example below, we provide a representation of how the pseudo-inverse minimizes $||A\\tilde{x} - y||$. Insert any rectangular matrix $A$ below and a vector $x$. As a result, you will see the resulting vector $y$, the generalized pseudo-inverse $\\tilde{G}$ and $\\tilde{x}$. You will observe that vector $\\tilde{x}$ will be very close, if not identical, to the vector you input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fb71ef-4b6b-4cca-9b30-5fbdbd1fd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ipywidgets==8.0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee2f40b-9e52-460b-b9ec-dbf982ec129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34075bde-2a00-45bc-aa8e-a990d9aecf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb33dbd024643398222f62a6cc53c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(Label(value='A = '), GridBox(children=(FloatText(value=0.0, layout=Layout(width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a11 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a12 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a13 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a21 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a22 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a23 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a31 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a32 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a33 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a41 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a42 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "a43 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "\n",
    "b1 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "b2 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "b3 = widgets.FloatText(value=0, description='', step=1, layout=widgets.Layout(width='50px'))\n",
    "\n",
    "matrix_inputs = widgets.GridBox([a11, a12, a13, a21, a22, a23, a31, a32, a33, a41, a42, a43], layout=widgets.Layout(grid_template_columns=\"60px 60px 60px\"))        \n",
    "vector_inputs = widgets.GridBox([b1, b2, b3], layout=widgets.Layout(grid_template_columns=\"60px\"))\n",
    "\n",
    "matrix_description = widgets.Label(\"A = \")\n",
    "vector_description = widgets.Label(\", x = \")\n",
    "\n",
    "matrix_hbox = widgets.HBox([matrix_description, matrix_inputs])\n",
    "vector_hbox = widgets.HBox([vector_description, vector_inputs])\n",
    "\n",
    "general_hbox = widgets.HBox([matrix_hbox, vector_hbox])\n",
    "\n",
    "display(general_hbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714f4aa5-ef05-48f7-a8e8-78b9dd6a7b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector y: [0. 0. 0. 0.] \n",
      "Pseudo-inverse: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]] \n",
      "Vector x~: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "matrixA = np.array([[a11.value, a12.value, a13.value],[a21.value, a22.value, a23.value],[a31.value, a32.value, a33.value],[a41.value, a42.value, a43.value]])\n",
    "vectorx = np.array([b1.value, b2.value, b3.value])\n",
    "\n",
    "y = np.matmul(matrixA,vectorx)\n",
    "pseudo_inv = np.linalg.pinv(matrixA)\n",
    "x_til = np.matmul(pseudo_inv,y)\n",
    "norm = np.linalg.norm((np.matmul(matrixA, x_til)) - y)\n",
    "\n",
    "print(f\"Vector y: {y} \\nPseudo-inverse: \\n {pseudo_inv} \\nVector x~: {x_til}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85dd71-1512-4b4d-bc9c-191884ecb015",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Rao C. Radhakrishna, Mitra Sujir Kumar. Generalized Inverse of Matrices and Its Applications. [place unknown]: John Wiley and Sons; 1971. ISBN: 0-470 70821-6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
